# -*- coding: utf-8 -*-
"""rembrand_astrocytoma_vs_normal.ipynb


Automatically generated by Colaboratory.


Original file is located at
   https://colab.research.google.com/drive/11636GhElAD0eMyPcRZK_Drl6PxORX1R9
"""


# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from matplotlib import cm
import seaborn as sns; sns.set()
import scipy


from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_samples
from sklearn import metrics
from sklearn.metrics import silhouette_score
from sklearn.metrics import accuracy_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from sklearn.metrics.cluster import adjusted_rand_score
import umap


# Loading the normalized data and formatting it into a readable input
df = pd.read_csv('expressions_for_astrocytoma_vs_normal.csv')
df.rename(columns={'Unnamed: 0':'probe_id'}, inplace=True)


metadata = pd.read_csv('metadata_for_all_astrocytoma_vs_normal.csv')
metadata = metadata[["Unnamed: 0", "disease:ch1"]]
metadata.rename(columns={'Unnamed: 0':'sample_name'}, inplace=True)
metadata = metadata.set_index('sample_name', drop=False).rename_axis(None)
metadata = metadata.iloc[: , 1:]


df_transposed = df.T
df_transposed = df_transposed.rename(columns=df_transposed.iloc[0])
df_transposed.drop(index=df_transposed.index[0],
       axis=0,
       inplace=True)


frames = [metadata, df_transposed]


result = pd.concat(frames, axis=1)


df = result


# Elementary analysis in the data
nRow, nCol = df.shape
print(f'There are {nRow} rows and {nCol} columns in the brain cancer data set')


# check for label distribution
label_count = df['disease:ch1'].value_counts()
label_count


# assign labels to variable y
y = df['disease:ch1']


# select feature data for clustering
data = df.iloc[:,1:].values
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)


### k-Means Clustering
# Calculate the cluster errors for clusters from 1 to 15
cluster_range = range( 1, 20 )
cluster_errors = []
for num_clusters in cluster_range:
 clusters = KMeans(num_clusters, n_init = 10 )
 clusters.fit(scaled_data)
 labels = clusters.labels_
 centroids = clusters.cluster_centers_
 cluster_errors.append( clusters.inertia_ )
clusters_df = pd.DataFrame( { "num_clusters":cluster_range, "cluster_errors": cluster_errors } )
clusters_df[0:20]


# Elbow plot
plt.figure(figsize=(12,6))
plt.plot(clusters_df.num_clusters, clusters_df.cluster_errors, marker = "o" )
plt.xlabel('Number of clusters', fontsize=12, fontweight='bold')
plt.ylabel('Cluster error', fontsize=12, fontweight='bold')
plt.title('Elbow plot for determining number of clusters', fontsize=14, fontweight='bold')
plt.savefig('elbowplot.png')


# instantiate KMeans object
km = KMeans(n_clusters=3, random_state=0)


# predict the cluster labels
labels = km.fit_predict(scaled_data)


km.cluster_centers_.shape
centroids = km.cluster_centers_


## creating a new dataframe only for labels and converting it into categorical variable
df_labels = pd.DataFrame(km.labels_ , columns = list(['label']))
df_labels['label'] = df_labels['label'].astype('category')
df_labels['sample_name'] = df.index
df_labels = df_labels.set_index('sample_name', drop=False).rename_axis(None)
df_labels = df_labels.iloc[: , :-1]


# Joining the label dataframe with the original data frame.
df_labeled = df.join(df_labels)
df_labeled.head()
df_labeled['label'].value_counts()


# number of permutations of the labels to find which cluster associates with which label
def find_permutation(n_clusters, real_labels, labels):
   permutation=[]
   for i in range(n_clusters):
       idx = labels == i
       new_label=scipy.stats.mode(real_labels[idx])[0][0]  # Choose the most common label among data points in the cluster
       permutation.append(new_label)
   return permutation


permutation = find_permutation(3, y, km.labels_)
new_labels = [ permutation[label] for label in km.labels_]   # permute the labels
print("Accuracy score is", accuracy_score(y, new_labels))


# plot confusion matrix
mat = confusion_matrix(y, new_labels)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
           xticklabels=permutation,
           yticklabels=permutation)
plt.xlabel('true label')
plt.ylabel('predicted label');
plt.savefig('confustion_matrix_1')


rand_index = adjusted_rand_score(labels_true = y, labels_pred = labels)
print('The Rand index is', round(rand_index, 2))


# In order to find the number of dimensions explaining most of the variety in the data, plot cumulative explained variance
pca_plot = PCA().fit(scaled_data)
plt.plot(np.cumsum(pca_plot.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');


# t-SNE plot
tsne = TSNE(random_state=0)
tsne_result = tsne.fit_transform(data)
xi = tsne_result[:, 0]
yi = tsne_result[:, 1]


plt.figure(figsize=(16,10))
sns.scatterplot(
   x=xi, y=yi,
   hue=y,
   legend="full",
   alpha=1
)
plt.savefig('t-SNE_plot.png')


tsne_scaled = TSNE(random_state=0)
tsne_result_scaled = tsne.fit_transform(scaled_data)
xi_scaled = tsne_result_scaled[:, 0]
yi_scaled = tsne_result_scaled[:, 1]


plt.figure(figsize=(16,10))
sns.scatterplot(
   x=xi_scaled, y=yi_scaled,
   hue=y,
   legend="full",
   alpha=1
)


km_tsne = KMeans(n_clusters = 3, random_state=0)


# predict the cluster labels
labels_tsne = km_tsne.fit_predict(tsne_result)
labels_tsne.size
labels_tsne


## creating a new dataframe only for labels and converting it into categorical variable
df_labels_tsne = pd.DataFrame(km_tsne.labels_ , columns = list(['label']))
df_labels_tsne['label'] = df_labels_tsne['label'].astype('category')
df_labels_tsne['sample_name'] = df.index
df_labels_tsne = df_labels_tsne.set_index('sample_name', drop=False).rename_axis(None)
df_labels_tsne = df_labels_tsne.iloc[: , :-1]
df_labels_tsne.head()
df_labels_tsne['label'].value_counts()


permutation = find_permutation(3, y, km_tsne.labels_)
new_labels = [ permutation[label] for label in km_tsne.labels_]   # permute the labels
print("Accuracy score is", accuracy_score(y, new_labels))


# plot confusion matrix
mat = confusion_matrix(y, new_labels)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
           xticklabels=permutation,
           yticklabels=permutation)
plt.xlabel('true label')
plt.ylabel('predicted label');
plt.savefig('confustion_matrix_1')


rand_index = adjusted_rand_score(labels_true = y, labels_pred = labels_tsne)
print('The Rand index is', round(rand_index, 2))


clusterable_embedding = umap.UMAP(
   n_neighbors=30,
   min_dist=0.0,
   n_components=2,
   random_state=42,
).fit_transform(data)


plt.figure(figsize=(16,10))
sns.scatterplot(
   x=clusterable_embedding[:, 0], y=clusterable_embedding[:, 1],
   hue=y,
   legend="full",
   alpha=1
)
plt.savefig('UMAP_plot.png')


km_umap = KMeans(n_clusters = 3)


# predict the cluster labels
labels_umap = km_umap.fit_predict(clusterable_embedding)


permutation = find_permutation(3, y, km_umap.labels_)
new_labels = [ permutation[label] for label in km_umap.labels_]   # permute the labels
print("Accuracy score is", accuracy_score(y, new_labels))


# plot confusion matrix
mat = confusion_matrix(y, new_labels)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
           xticklabels=permutation,
           yticklabels=permutation)
plt.xlabel('true label')
plt.ylabel('predicted label');
plt.savefig('confustion_matrix_3')


rand_index = adjusted_rand_score(labels_true = y, labels_pred = labels_umap)
print('The Rand index is', round(rand_index, 2))